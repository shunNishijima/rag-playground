# ============================
# streamlitã‚’ä½¿ã£ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼ˆæ¨¡ç¯„å›ç­”å¯¾å¿œç‰ˆï¼‰
# ============================
import time
import pathlib
import sys
import json
from datetime import datetime
import streamlit as st

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã® `src` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(pathlib.Path(__file__).resolve().parent.parent))

from backend.rag_hf import rag_chatbot

# ========== ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å®šç¾© ========== #
LOG_FILE = pathlib.Path("logs/ragas_eval_log.jsonl")
LOG_FILE.parent.mkdir(parents=True, exist_ok=True)

# ========== å‚ç…§å›ç­”ï¼ˆæ¨¡ç¯„è§£ç­”ï¼‰èª­ã¿è¾¼ã¿ ========== #
REFERENCE_FILE = pathlib.Path("data/reference.json")
if REFERENCE_FILE.exists():
    with REFERENCE_FILE.open("r", encoding="utf-8") as f:
        reference_data = json.load(f)
    reference_dict = {item["question"]: item["reference"] for item in reference_data}
else:
    reference_dict = {}

# ========== RAGASè©•ä¾¡ç”¨ãƒ­ã‚°é–¢æ•° ========== #
def log_ragas_sample(question: str, response: dict, reference: str):
    sample = {
        "question": question,
        "answer": response["answer"],
        "contexts": [doc["page_content"] for doc in response["source_documents"]],
        "reference": reference,
        "timestamp": datetime.now().isoformat()
    }

    with LOG_FILE.open("a", encoding="utf-8") as f:
        f.write(json.dumps(sample, ensure_ascii=False) + "\n")

# ========== Streamlit UIå®šç¾© ========== #
def render():
    st.set_page_config(page_title="æ³•å¾‹ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", page_icon="âš–ï¸")

    st.sidebar.header("è¨­å®š")
    use_openai = st.sidebar.radio(
        "åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        options=["HuggingFace", "OpenAI"],
        index=0,
        help="åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«"
    )
    use_openai = (use_openai == "OpenAI")

    st.title("âš–ï¸ æ³•å¾‹ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"], unsafe_allow_html=True)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å—ä»˜
    if prompt := st.chat_input("ã“ã“ã«æ³•å¾‹ç›¸è«‡ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                response = rag_chatbot(prompt, use_openai=use_openai)
                result = response["answer"]
                source_documents = response["source_documents"]

            # ğŸ”½ å‚ç…§å›ç­”ï¼ˆreferenceï¼‰å–å¾—
            reference = reference_dict.get(prompt, "ï¼ˆæ¨¡ç¯„è§£ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰")

            # ğŸ”½ RAGAS ãƒ­ã‚°è¨˜éŒ²
            log_ragas_sample(prompt, response, reference)

            # ã‚½ãƒ¼ã‚¹æ•´å½¢
            details_message = ""
            if source_documents:
                details_message += "<br><span style='font-size: small; color: gray;'>\nå‚è€ƒæ–‡æ›¸:</span><ul>"
                for doc in source_documents:
                    metadata = doc.get("metadata", {})
                    source_path = metadata.get("source") or metadata.get("id") or "ä¸æ˜"
                    title = pathlib.Path(source_path).name
                    details_message += f"<li><b>{title}</b></li>"
                details_message += "</ul>"
            else:
                details_message += "<span style='font-size: small; color: gray;'>å‚è€ƒè³‡æ–™ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</span>"

            # å›ç­”è¡¨ç¤º
            answer = f"{result}<br><br><b>ğŸ“‘ æ¨¡ç¯„è§£ç­”:</b> {reference}<br>{details_message}"
            st.markdown(answer, unsafe_allow_html=True)
            st.session_state.messages.append({"role": "assistant", "content": answer})
            st.rerun()

# ========== å®Ÿè¡Œ ========== #
if __name__ == "__main__":
    render()
