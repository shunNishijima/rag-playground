# ============================
# streamlitã‚’ä½¿ã£ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼ˆæ¨¡ç¯„å›ç­”å¯¾å¿œç‰ˆï¼‰
# ============================
import time
import pathlib
import sys
import json
from datetime import datetime
import streamlit as st

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã® `src` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(pathlib.Path(__file__).resolve().parent.parent))

from backend.rag_hf import (
    rag_chatbot,
    rag_chatbot_stream,
    get_vector_store_path,
    get_embedding_model
)

from langchain_community.vectorstores import FAISS

# ========== ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å®šç¾© ========== #
LOG_FILE = pathlib.Path("logs/ragas_eval_log.jsonl")
LOG_FILE.parent.mkdir(parents=True, exist_ok=True)

# ========== å‚ç…§å›ç­”ï¼ˆæ¨¡ç¯„è§£ç­”ï¼‰èª­ã¿è¾¼ã¿ ========== #
REFERENCE_FILE = pathlib.Path("data/reference.json")
if REFERENCE_FILE.exists():
    with REFERENCE_FILE.open("r", encoding="utf-8") as f:
        reference_data = json.load(f)
    reference_dict = {item["question"]: item["reference"] for item in reference_data}
else:
    reference_dict = {}

# ========== RAGASè©•ä¾¡ç”¨ãƒ­ã‚°é–¢æ•° ========== #
def log_ragas_sample(question: str, response: dict, reference: str):
    sample = {
        "question": question,
        "answer": response["answer"],
        "contexts": [doc["page_content"] for doc in response["source_documents"]],
        "reference": reference,
        "timestamp": datetime.now().isoformat()
    }

    with LOG_FILE.open("a", encoding="utf-8") as f:
        f.write(json.dumps(sample, ensure_ascii=False) + "\n")

# ========== Streamlit UIå®šç¾© ========== #
def render():
    st.set_page_config(page_title="æ³•å¾‹ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", page_icon="âš–ï¸")

    st.sidebar.header("è¨­å®š")
    use_openai = st.sidebar.radio(
        "åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        options=["HuggingFace", "OpenAI"],
        index=0,
        help="åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«"
    )
    use_openai = (use_openai == "OpenAI")

    st.title("âš–ï¸ æ³•å¾‹ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"], unsafe_allow_html=True)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å—ä»˜
    if prompt := st.chat_input("ã“ã“ã«æ³•å¾‹ç›¸è«‡ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # with st.chat_message("assistant"):
        #     with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
        #         response = rag_chatbot(prompt, use_openai=use_openai)
        #         result = response["answer"]
        #         source_documents = response["source_documents"]

        #     # ğŸ”½ å‚ç…§å›ç­”ï¼ˆreferenceï¼‰å–å¾—
        #     reference = reference_dict.get(prompt, "ï¼ˆæ¨¡ç¯„è§£ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰")

        #     # ğŸ”½ RAGAS ãƒ­ã‚°è¨˜éŒ²
        #     log_ragas_sample(prompt, response, reference)

        #     # ã‚½ãƒ¼ã‚¹æ•´å½¢
        #     details_message = ""
        #     if source_documents:
        #         details_message += "<br><span style='font-size: small; color: gray;'>\nå‚è€ƒæ–‡æ›¸:</span><ul>"
        #         for doc in source_documents:
        #             metadata = doc.get("metadata", {})
        #             source_path = metadata.get("source") or metadata.get("id") or "ä¸æ˜"
        #             title = pathlib.Path(source_path).name
        #             details_message += f"<li><b>{title}</b></li>"
        #         details_message += "</ul>"
        #     else:
        #         details_message += "<span style='font-size: small; color: gray;'>å‚è€ƒè³‡æ–™ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</span>"

        #     # å›ç­”è¡¨ç¤º
        #     answer = f"{result}<br><br><b>ğŸ“‘ æ¨¡ç¯„è§£ç­”:</b> {reference}<br>{details_message}"
        #     st.markdown(answer, unsafe_allow_html=True)
        #     st.session_state.messages.append({"role": "assistant", "content": answer})
        #     st.rerun()
            
        with st.chat_message("assistant"):
            with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):

                # âœ… relevant documents ã‚’å…ˆã«å–å¾—
                vector_store_path = get_vector_store_path(use_openai)
                embedding_model = get_embedding_model(use_openai)
                faiss_db = FAISS.load_local(vector_store_path, embedding_model, allow_dangerous_deserialization=True)
                retriever = faiss_db.as_retriever(search_kwargs={"k": 3})
                docs = retriever.get_relevant_documents(prompt)

                # âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›
                response_text = ""
                response_area = st.empty()
                for chunk in rag_chatbot_stream(prompt, use_openai=use_openai):
                    if chunk == "[END]":
                        break
                    response_text += chunk
                    response_area.markdown(response_text)

                # ğŸ”½ å‚ç…§å›ç­”
                reference = reference_dict.get(prompt, "ï¼ˆæ¨¡ç¯„è§£ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰")

                # ğŸ”½ RAGAS ãƒ­ã‚°è¨˜éŒ²
                log_ragas_sample(prompt, {
                    "answer": response_text,
                    "source_documents": [
                        {"page_content": doc.page_content, "metadata": doc.metadata} for doc in docs
                    ]
                }, reference)

                # ğŸ”½ ã‚½ãƒ¼ã‚¹æ•´å½¢
                details_message = "<br><span style='font-size: small; color: gray;'>\nå‚è€ƒæ–‡æ›¸:</span><ul>"
                for doc in docs:
                    metadata = doc.metadata
                    source_path = metadata.get("source") or metadata.get("id") or "ä¸æ˜"
                    title = pathlib.Path(source_path).name
                    details_message += f"<li><b>{title}</b></li>"
                details_message += "</ul>"

                # ğŸ”½ æœ€çµ‚å›ç­”æ•´å½¢ã—ã¦è¨˜éŒ²
                answer = f"{response_text}<br><br><b>ğŸ“‘ æ¨¡ç¯„è§£ç­”:</b> {reference}<br>{details_message}"
                st.session_state.messages.append({"role": "assistant", "content": answer})
                st.rerun()

# ========== å®Ÿè¡Œ ========== #
if __name__ == "__main__":
    render()
